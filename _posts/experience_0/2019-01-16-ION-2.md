---
layout: post
title: To Mitigate the Delay of Cue Delivering
subtitle: -- Develop FPGA-based Sound Generator System
---
![](/assets/images/ION_2_design.svg)

<!--more-->

with Professor [Ninglong Xu](http://english.cebsit.cas.cn/LABORATORIES/XuNingLong/Research/), Institute of Neuroscience, Chinese Academy of Science

### The Problem

It's very important to deliver flexible cue signal within a short and reliable delay in many neuroscience research circumstances, including electrophysiology recording, calcium imaging, photoinhibition, and especially in the closed-loop neuroscience designs.

However, a typical PC-based signal delivering system usually suffers from a 20ms delay unless expensive commercial equipment is employed. An alternative is the Direct Digital Synthesis (DDS) chips, but it limits the waveform to be only sinusoid-based.

The desired system has two requirements: the flexibility to deliver signals of any **arbitrary waveforms**, the **acceptable and reliable response delay**.

### The Approach

Iâ€™m customizing an **FPFA**-based Sound Generator System (SGS) to suit the need of Xu's lab. The system consists of an FPGA development board with a **DDR3 SDRAM** for data storage, a **USB** interface to communicate with the PC host (I use api provided by Frontpanel). Output signals are sent to a **DAC** chip and an **amplifier**. 

For FPGA coding, a finite state machine (**FSM**) is designed to issue commands about writing and reading data. Before a training session starts, the sound data/parameters should be sent from PC to FPGA, and saved in DDR3. The previous training protocol in the lab is controlled by Arduino. So I make my SGS compatible with Arduino (with **SPI** protocol -- Arduino as the master and FPGA as the slave). During each trial, a trigger from Arduino is received by the FPGA, and the parameters/data are retrieved from DDR3. FPGA needs to test conditions before taking actions and align clocking among different parts. Then the digital sound data is turned into analog waveform and played out by the DAC chip.

The products we used are: Opal Kelly development board [XEM7320](https://opalkelly.com/products/xem7320/) with Xilinx [Artix-7](https://www.xilinx.com/products/silicon-devices/fpga/artix-7.html) FPGA and Micro DDR3 SDRAM [MT41K256M16TW](https://www.micron.com/products/dram/ddr3-sdram/part-catalog/mt41k256m16tw-107-it); Opal Kelly DAC chip [SZG-DAC-AD911X](https://opalkelly.com/products/szg-dac-ad911x/).

The project is still in development, and the [code](https://github.com/xuefei-wang/Sound-Generator-Module) can be found in Github. 

### The Innovations and Discoveries

The system provides minimal and reliable signal delivering latency, and opens up possibilities for various experiment design. I also created controllers for different parts like DDR3 SDRAM and DAC chips, which can be re-used in other hardware systems (for example random-access two-phone system).